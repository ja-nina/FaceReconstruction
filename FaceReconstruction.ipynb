{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Reconstruction\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tested models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.basic.Discriminator import Discriminator as BasicDiscriminator\n",
    "from models.basic.Generator import Generator as BasicGenerator\n",
    "from models.basic_2.Discriminator import  Discriminator as BasicDiscriminator_2\n",
    "from models.basic_2.Generator import Generator as BasicGenerator_2\n",
    "from models.AOT.Discriminator import Discriminator as Discriminator_AOT\n",
    "from models.AOT.Generator import Generator as BasicGenerator_AOT\n",
    "from models.double_gan.UNet import UNet as DoubleDiscriminator_UNet\n",
    "from models.double_gan.UNet_maskAware import UNet_maskAware as DoubleGenerator_UNet\n",
    "from models.double_gan.Generator import Generator as DoubleGenerator_AOT\n",
    "from classes.Experiment import Experiment\n",
    "from train import train\n",
    "from config import n_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments = [  Experiment(name = 'Overfit_Study_Baseline',\n",
    "                              generator_models = [BasicGenerator_2],\n",
    "                              discriminator_models = [DoubleDiscriminator_UNet],\n",
    "                              generate_whole_image= False,\n",
    "                              overfittingStudy=True,\n",
    "                              pretrain = True,\n",
    "                              dropout_generator = 0.01,\n",
    "                              dropout_discriminator = 0.01,\n",
    "                              epochs = n_epochs),\n",
    "                Experiment(name = 'Overfit_Study_DoubleUnet',\n",
    "                              generator_models = [DoubleGenerator_UNet],\n",
    "                              discriminator_models = [DoubleDiscriminator_UNet],\n",
    "                              generate_whole_image= True,\n",
    "                              overfittingStudy=True,\n",
    "                              pretrain = True,\n",
    "                              dropout_generator = 0.01,\n",
    "                              dropout_discriminator = 0.01,\n",
    "                              epochs = n_epochs),\n",
    "                Experiment(name = 'Overfit_Study_AOT',\n",
    "                              generator_models = [BasicGenerator_AOT],\n",
    "                              discriminator_models = [DoubleDiscriminator_UNet],\n",
    "                              generate_whole_image= True,\n",
    "                              overfittingStudy=True,\n",
    "                              pretrain = True,\n",
    "                              dropout_generator = 0.1,\n",
    "                              dropout_discriminator = 0.1,\n",
    "                              epochs = n_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/zukowskanina1/FaceReconstruction/e/FAC-111\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ismyn\\Anaconda3\\envs\\FaceReconstruction\\lib\\site-packages\\neptune\\new\\attributes\\attribute.py:64: NeptuneDeprecationWarning: The object you're logging will be implicitly cast to a string. We'll end support of this behavior in `neptune-client==1.0.0`. To log the object as a string, use `str(object)` instead.\n",
      "  return self.assign(value, wait)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALISING WEIGHTS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0 : 100%|██████████| 13/13 [00:11<00:00,  1.10it/s, disc_loss=0.473, gen_adv_loss=0.952, gen_pixel_loss=0.398]\n",
      "Training Epoch 1 : 100%|██████████| 13/13 [00:05<00:00,  2.42it/s, disc_loss=0.416, gen_adv_loss=0.84, gen_pixel_loss=0.375] \n",
      "Training Epoch 2 : 100%|██████████| 13/13 [00:05<00:00,  2.19it/s, disc_loss=0.369, gen_adv_loss=0.768, gen_pixel_loss=0.391]\n",
      "Training Epoch 3 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.324, gen_adv_loss=0.739, gen_pixel_loss=0.379]\n",
      "Training Epoch 4 : 100%|██████████| 13/13 [00:05<00:00,  2.43it/s, disc_loss=0.284, gen_adv_loss=0.72, gen_pixel_loss=0.375] \n",
      "Training Epoch 5 : 100%|██████████| 13/13 [00:05<00:00,  2.40it/s, disc_loss=0.257, gen_adv_loss=0.653, gen_pixel_loss=0.368]\n",
      "Training Epoch 6 : 100%|██████████| 13/13 [00:05<00:00,  2.38it/s, disc_loss=0.238, gen_adv_loss=0.613, gen_pixel_loss=0.353]\n",
      "Training Epoch 7 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.21, gen_adv_loss=0.605, gen_pixel_loss=0.371] \n",
      "Training Epoch 8 : 100%|██████████| 13/13 [00:06<00:00,  2.16it/s, disc_loss=0.209, gen_adv_loss=0.557, gen_pixel_loss=0.353]\n",
      "Training Epoch 9 : 100%|██████████| 13/13 [00:05<00:00,  2.20it/s, disc_loss=0.185, gen_adv_loss=0.559, gen_pixel_loss=0.347]\n",
      "Training Epoch 10 : 100%|██████████| 13/13 [00:06<00:00,  2.03it/s, disc_loss=0.167, gen_adv_loss=0.574, gen_pixel_loss=0.346]\n",
      "Training Epoch 11 : 100%|██████████| 13/13 [00:10<00:00,  1.23it/s, disc_loss=0.182, gen_adv_loss=0.519, gen_pixel_loss=0.337]\n",
      "Training Epoch 12 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.166, gen_adv_loss=0.51, gen_pixel_loss=0.331] \n",
      "Training Epoch 13 : 100%|██████████| 13/13 [00:06<00:00,  1.99it/s, disc_loss=0.161, gen_adv_loss=0.521, gen_pixel_loss=0.333]\n",
      "Training Epoch 14 : 100%|██████████| 13/13 [00:06<00:00,  1.99it/s, disc_loss=0.14, gen_adv_loss=0.559, gen_pixel_loss=0.341] \n",
      "Training Epoch 15 : 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, disc_loss=0.197, gen_adv_loss=0.427, gen_pixel_loss=0.334]\n",
      "Training Epoch 16 : 100%|██████████| 13/13 [00:06<00:00,  1.95it/s, disc_loss=0.185, gen_adv_loss=0.406, gen_pixel_loss=0.329]\n",
      "Training Epoch 17 : 100%|██████████| 13/13 [00:06<00:00,  1.93it/s, disc_loss=0.149, gen_adv_loss=0.464, gen_pixel_loss=0.317]\n",
      "Training Epoch 18 : 100%|██████████| 13/13 [00:08<00:00,  1.53it/s, disc_loss=0.157, gen_adv_loss=0.461, gen_pixel_loss=0.316]\n",
      "Training Epoch 19 : 100%|██████████| 13/13 [00:09<00:00,  1.42it/s, disc_loss=0.148, gen_adv_loss=0.459, gen_pixel_loss=0.32] \n",
      "Training Epoch 20 : 100%|██████████| 13/13 [00:06<00:00,  2.14it/s, disc_loss=0.208, gen_adv_loss=0.391, gen_pixel_loss=0.321]\n",
      "Training Epoch 21 : 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, disc_loss=0.156, gen_adv_loss=0.446, gen_pixel_loss=0.311]\n",
      "Training Epoch 22 : 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, disc_loss=0.158, gen_adv_loss=0.434, gen_pixel_loss=0.304]\n",
      "Training Epoch 23 : 100%|██████████| 13/13 [00:10<00:00,  1.24it/s, disc_loss=0.173, gen_adv_loss=0.363, gen_pixel_loss=0.304]\n",
      "Training Epoch 24 : 100%|██████████| 13/13 [00:06<00:00,  1.91it/s, disc_loss=0.156, gen_adv_loss=0.474, gen_pixel_loss=0.31] \n",
      "Training Epoch 25 : 100%|██████████| 13/13 [00:06<00:00,  1.89it/s, disc_loss=0.255, gen_adv_loss=0.29, gen_pixel_loss=0.306] \n",
      "Training Epoch 26 : 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, disc_loss=0.253, gen_adv_loss=0.259, gen_pixel_loss=0.299]\n",
      "Training Epoch 27 : 100%|██████████| 13/13 [00:07<00:00,  1.81it/s, disc_loss=0.249, gen_adv_loss=0.266, gen_pixel_loss=0.296]\n",
      "Training Epoch 28 : 100%|██████████| 13/13 [00:06<00:00,  1.92it/s, disc_loss=0.243, gen_adv_loss=0.275, gen_pixel_loss=0.305]\n",
      "Training Epoch 29 : 100%|██████████| 13/13 [00:06<00:00,  1.89it/s, disc_loss=0.245, gen_adv_loss=0.271, gen_pixel_loss=0.301]\n",
      "Training Epoch 30 : 100%|██████████| 13/13 [00:10<00:00,  1.25it/s, disc_loss=0.252, gen_adv_loss=0.254, gen_pixel_loss=0.301]\n",
      "Training Epoch 31 : 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, disc_loss=0.249, gen_adv_loss=0.292, gen_pixel_loss=0.308]\n",
      "Training Epoch 32 : 100%|██████████| 13/13 [00:07<00:00,  1.72it/s, disc_loss=0.245, gen_adv_loss=0.307, gen_pixel_loss=0.299]\n",
      "Training Epoch 33 : 100%|██████████| 13/13 [00:06<00:00,  2.06it/s, disc_loss=0.226, gen_adv_loss=0.31, gen_pixel_loss=0.29]  \n",
      "Training Epoch 34 : 100%|██████████| 13/13 [00:09<00:00,  1.36it/s, disc_loss=0.225, gen_adv_loss=0.305, gen_pixel_loss=0.288]\n",
      "Training Epoch 35 : 100%|██████████| 13/13 [00:06<00:00,  1.99it/s, disc_loss=0.228, gen_adv_loss=0.29, gen_pixel_loss=0.3]   \n",
      "Training Epoch 36 : 100%|██████████| 13/13 [00:06<00:00,  2.03it/s, disc_loss=0.217, gen_adv_loss=0.311, gen_pixel_loss=0.283]\n",
      "Training Epoch 37 : 100%|██████████| 13/13 [00:07<00:00,  1.82it/s, disc_loss=0.215, gen_adv_loss=0.333, gen_pixel_loss=0.299]\n",
      "Training Epoch 38 : 100%|██████████| 13/13 [00:10<00:00,  1.23it/s, disc_loss=0.198, gen_adv_loss=0.34, gen_pixel_loss=0.308] \n",
      "Training Epoch 39 : 100%|██████████| 13/13 [00:07<00:00,  1.74it/s, disc_loss=0.198, gen_adv_loss=0.326, gen_pixel_loss=0.303]\n",
      "Training Epoch 40 : 100%|██████████| 13/13 [00:07<00:00,  1.80it/s, disc_loss=0.23, gen_adv_loss=0.3, gen_pixel_loss=0.293]   \n",
      "Training Epoch 41 : 100%|██████████| 13/13 [00:07<00:00,  1.67it/s, disc_loss=0.183, gen_adv_loss=0.351, gen_pixel_loss=0.289]\n",
      "Training Epoch 42 : 100%|██████████| 13/13 [00:11<00:00,  1.16it/s, disc_loss=0.19, gen_adv_loss=0.356, gen_pixel_loss=0.289] \n",
      "Training Epoch 43 : 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, disc_loss=0.224, gen_adv_loss=0.337, gen_pixel_loss=0.296]\n",
      "Training Epoch 44 : 100%|██████████| 13/13 [00:07<00:00,  1.74it/s, disc_loss=0.237, gen_adv_loss=0.314, gen_pixel_loss=0.28] \n",
      "Training Epoch 45 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.226, gen_adv_loss=0.342, gen_pixel_loss=0.278]\n",
      "Training Epoch 46 : 100%|██████████| 13/13 [00:11<00:00,  1.15it/s, disc_loss=0.214, gen_adv_loss=0.281, gen_pixel_loss=0.283]\n",
      "Training Epoch 47 : 100%|██████████| 13/13 [00:07<00:00,  1.79it/s, disc_loss=0.223, gen_adv_loss=0.275, gen_pixel_loss=0.29] \n",
      "Training Epoch 48 : 100%|██████████| 13/13 [00:07<00:00,  1.77it/s, disc_loss=0.217, gen_adv_loss=0.296, gen_pixel_loss=0.292]\n",
      "Training Epoch 49 : 100%|██████████| 13/13 [00:07<00:00,  1.72it/s, disc_loss=0.209, gen_adv_loss=0.282, gen_pixel_loss=0.283]\n",
      "Training Epoch 50 : 100%|██████████| 13/13 [00:10<00:00,  1.27it/s, disc_loss=0.223, gen_adv_loss=0.298, gen_pixel_loss=0.287]\n",
      "Training Epoch 51 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.185, gen_adv_loss=0.338, gen_pixel_loss=0.286]\n",
      "Training Epoch 52 : 100%|██████████| 13/13 [00:07<00:00,  1.68it/s, disc_loss=0.234, gen_adv_loss=0.271, gen_pixel_loss=0.28] \n",
      "Training Epoch 53 : 100%|██████████| 13/13 [00:11<00:00,  1.11it/s, disc_loss=0.225, gen_adv_loss=0.431, gen_pixel_loss=0.28] \n",
      "Training Epoch 54 : 100%|██████████| 13/13 [00:07<00:00,  1.81it/s, disc_loss=0.2, gen_adv_loss=0.283, gen_pixel_loss=0.282]  \n",
      "Training Epoch 55 : 100%|██████████| 13/13 [00:06<00:00,  2.05it/s, disc_loss=0.216, gen_adv_loss=0.277, gen_pixel_loss=0.276]\n",
      "Training Epoch 56 : 100%|██████████| 13/13 [00:06<00:00,  1.98it/s, disc_loss=0.218, gen_adv_loss=0.376, gen_pixel_loss=0.284]\n",
      "Training Epoch 57 : 100%|██████████| 13/13 [00:11<00:00,  1.13it/s, disc_loss=0.263, gen_adv_loss=0.44, gen_pixel_loss=0.294] \n",
      "Training Epoch 58 : 100%|██████████| 13/13 [00:08<00:00,  1.60it/s, disc_loss=0.212, gen_adv_loss=0.379, gen_pixel_loss=0.275]\n",
      "Training Epoch 59 : 100%|██████████| 13/13 [00:07<00:00,  1.76it/s, disc_loss=0.214, gen_adv_loss=0.241, gen_pixel_loss=0.29] \n",
      "Training Epoch 60 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.243, gen_adv_loss=0.373, gen_pixel_loss=0.277]\n",
      "Training Epoch 61 : 100%|██████████| 13/13 [00:10<00:00,  1.28it/s, disc_loss=0.234, gen_adv_loss=0.372, gen_pixel_loss=0.271]\n",
      "Training Epoch 62 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.208, gen_adv_loss=0.398, gen_pixel_loss=0.288]\n",
      "Training Epoch 63 : 100%|██████████| 13/13 [00:08<00:00,  1.50it/s, disc_loss=0.217, gen_adv_loss=0.368, gen_pixel_loss=0.277]\n",
      "Training Epoch 64 : 100%|██████████| 13/13 [00:07<00:00,  1.69it/s, disc_loss=0.203, gen_adv_loss=0.31, gen_pixel_loss=0.275] \n",
      "Training Epoch 65 : 100%|██████████| 13/13 [00:09<00:00,  1.37it/s, disc_loss=0.166, gen_adv_loss=0.383, gen_pixel_loss=0.274]\n",
      "Training Epoch 66 : 100%|██████████| 13/13 [00:07<00:00,  1.76it/s, disc_loss=0.161, gen_adv_loss=0.361, gen_pixel_loss=0.271]\n",
      "Training Epoch 67 : 100%|██████████| 13/13 [00:06<00:00,  1.92it/s, disc_loss=0.194, gen_adv_loss=0.292, gen_pixel_loss=0.266]\n",
      "Training Epoch 68 : 100%|██████████| 13/13 [00:06<00:00,  1.87it/s, disc_loss=0.163, gen_adv_loss=0.363, gen_pixel_loss=0.27] \n",
      "Training Epoch 69 : 100%|██████████| 13/13 [00:11<00:00,  1.16it/s, disc_loss=0.194, gen_adv_loss=0.286, gen_pixel_loss=0.282]\n",
      "Training Epoch 70 : 100%|██████████| 13/13 [00:06<00:00,  1.94it/s, disc_loss=0.12, gen_adv_loss=0.465, gen_pixel_loss=0.274] \n",
      "Training Epoch 71 : 100%|██████████| 13/13 [00:08<00:00,  1.61it/s, disc_loss=0.155, gen_adv_loss=0.373, gen_pixel_loss=0.291]\n",
      "Training Epoch 72 : 100%|██████████| 13/13 [00:08<00:00,  1.57it/s, disc_loss=0.152, gen_adv_loss=0.403, gen_pixel_loss=0.266]\n",
      "Training Epoch 73 : 100%|██████████| 13/13 [00:13<00:00,  1.06s/it, disc_loss=0.136, gen_adv_loss=0.387, gen_pixel_loss=0.28] \n",
      "Training Epoch 74 : 100%|██████████| 13/13 [00:06<00:00,  1.92it/s, disc_loss=0.176, gen_adv_loss=0.415, gen_pixel_loss=0.267]\n",
      "Training Epoch 75 : 100%|██████████| 13/13 [00:07<00:00,  1.83it/s, disc_loss=0.129, gen_adv_loss=0.441, gen_pixel_loss=0.262]\n",
      "Training Epoch 76 : 100%|██████████| 13/13 [00:11<00:00,  1.08it/s, disc_loss=0.194, gen_adv_loss=0.317, gen_pixel_loss=0.27] \n",
      "Training Epoch 77 : 100%|██████████| 13/13 [00:08<00:00,  1.57it/s, disc_loss=0.231, gen_adv_loss=0.425, gen_pixel_loss=0.269]\n",
      "Training Epoch 78 : 100%|██████████| 13/13 [00:06<00:00,  1.86it/s, disc_loss=0.156, gen_adv_loss=0.414, gen_pixel_loss=0.266]\n",
      "Training Epoch 79 : 100%|██████████| 13/13 [00:08<00:00,  1.59it/s, disc_loss=0.153, gen_adv_loss=0.373, gen_pixel_loss=0.27] \n",
      "Training Epoch 80 : 100%|██████████| 13/13 [00:13<00:00,  1.03s/it, disc_loss=0.234, gen_adv_loss=0.249, gen_pixel_loss=0.264]\n",
      "Training Epoch 81 : 100%|██████████| 13/13 [00:07<00:00,  1.64it/s, disc_loss=0.185, gen_adv_loss=0.347, gen_pixel_loss=0.264]\n",
      "Training Epoch 82 : 100%|██████████| 13/13 [00:07<00:00,  1.64it/s, disc_loss=0.16, gen_adv_loss=0.434, gen_pixel_loss=0.259] \n",
      "Training Epoch 83 : 100%|██████████| 13/13 [00:06<00:00,  1.87it/s, disc_loss=0.194, gen_adv_loss=0.332, gen_pixel_loss=0.267]\n",
      "Training Epoch 84 : 100%|██████████| 13/13 [00:10<00:00,  1.29it/s, disc_loss=0.155, gen_adv_loss=0.42, gen_pixel_loss=0.261] \n",
      "Training Epoch 85 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.188, gen_adv_loss=0.408, gen_pixel_loss=0.269]\n",
      "Training Epoch 86 : 100%|██████████| 13/13 [00:06<00:00,  1.97it/s, disc_loss=0.211, gen_adv_loss=0.353, gen_pixel_loss=0.256]\n",
      "Training Epoch 87 : 100%|██████████| 13/13 [00:07<00:00,  1.63it/s, disc_loss=0.218, gen_adv_loss=0.608, gen_pixel_loss=0.258]\n",
      "Training Epoch 88 : 100%|██████████| 13/13 [00:09<00:00,  1.35it/s, disc_loss=0.187, gen_adv_loss=0.409, gen_pixel_loss=0.259]\n",
      "Training Epoch 89 : 100%|██████████| 13/13 [00:06<00:00,  1.96it/s, disc_loss=0.255, gen_adv_loss=0.185, gen_pixel_loss=0.269]\n",
      "Training Epoch 90 : 100%|██████████| 13/13 [00:06<00:00,  1.89it/s, disc_loss=0.241, gen_adv_loss=0.184, gen_pixel_loss=0.265]\n",
      "Training Epoch 91 : 100%|██████████| 13/13 [00:06<00:00,  1.94it/s, disc_loss=0.228, gen_adv_loss=0.194, gen_pixel_loss=0.269]\n",
      "Training Epoch 92 : 100%|██████████| 13/13 [00:10<00:00,  1.26it/s, disc_loss=0.193, gen_adv_loss=0.258, gen_pixel_loss=0.271]\n",
      "Training Epoch 93 : 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, disc_loss=0.195, gen_adv_loss=0.348, gen_pixel_loss=0.259]\n",
      "Training Epoch 94 : 100%|██████████| 13/13 [00:07<00:00,  1.70it/s, disc_loss=0.167, gen_adv_loss=0.477, gen_pixel_loss=0.263]\n",
      "Training Epoch 95 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.171, gen_adv_loss=0.294, gen_pixel_loss=0.264]\n",
      "Training Epoch 96 : 100%|██████████| 13/13 [00:11<00:00,  1.12it/s, disc_loss=0.203, gen_adv_loss=0.444, gen_pixel_loss=0.26] \n",
      "Training Epoch 97 : 100%|██████████| 13/13 [00:08<00:00,  1.49it/s, disc_loss=0.138, gen_adv_loss=0.432, gen_pixel_loss=0.259]\n",
      "Training Epoch 98 : 100%|██████████| 13/13 [00:08<00:00,  1.54it/s, disc_loss=0.188, gen_adv_loss=0.294, gen_pixel_loss=0.256]\n",
      "Training Epoch 99 : 100%|██████████| 13/13 [00:07<00:00,  1.77it/s, disc_loss=0.194, gen_adv_loss=0.342, gen_pixel_loss=0.253]\n",
      "Training Epoch 100 : 100%|██████████| 13/13 [00:10<00:00,  1.26it/s, disc_loss=0.239, gen_adv_loss=0.338, gen_pixel_loss=0.259]\n",
      "Training Epoch 101 : 100%|██████████| 13/13 [00:06<00:00,  1.87it/s, disc_loss=0.2, gen_adv_loss=0.39, gen_pixel_loss=0.256]   \n",
      "Training Epoch 102 : 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, disc_loss=0.189, gen_adv_loss=0.382, gen_pixel_loss=0.265]\n",
      "Training Epoch 103 : 100%|██████████| 13/13 [00:12<00:00,  1.07it/s, disc_loss=0.206, gen_adv_loss=0.459, gen_pixel_loss=0.268]\n",
      "Training Epoch 104 : 100%|██████████| 13/13 [00:08<00:00,  1.59it/s, disc_loss=0.165, gen_adv_loss=0.443, gen_pixel_loss=0.253]\n",
      "Training Epoch 105 : 100%|██████████| 13/13 [00:08<00:00,  1.49it/s, disc_loss=0.172, gen_adv_loss=0.34, gen_pixel_loss=0.262] \n",
      "Training Epoch 106 : 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, disc_loss=0.204, gen_adv_loss=0.433, gen_pixel_loss=0.257]\n",
      "Training Epoch 107 : 100%|██████████| 13/13 [00:11<00:00,  1.15it/s, disc_loss=0.141, gen_adv_loss=0.511, gen_pixel_loss=0.254]\n",
      "Training Epoch 108 : 100%|██████████| 13/13 [00:07<00:00,  1.73it/s, disc_loss=0.201, gen_adv_loss=0.233, gen_pixel_loss=0.269]\n",
      "Training Epoch 109 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.196, gen_adv_loss=0.533, gen_pixel_loss=0.26] \n",
      "Training Epoch 110 : 100%|██████████| 13/13 [00:08<00:00,  1.54it/s, disc_loss=0.205, gen_adv_loss=0.369, gen_pixel_loss=0.252]\n",
      "Training Epoch 111 : 100%|██████████| 13/13 [00:12<00:00,  1.07it/s, disc_loss=0.187, gen_adv_loss=0.416, gen_pixel_loss=0.249]\n",
      "Training Epoch 112 : 100%|██████████| 13/13 [00:07<00:00,  1.64it/s, disc_loss=0.162, gen_adv_loss=0.42, gen_pixel_loss=0.251] \n",
      "Training Epoch 113 : 100%|██████████| 13/13 [00:08<00:00,  1.54it/s, disc_loss=0.21, gen_adv_loss=0.38, gen_pixel_loss=0.257]  \n",
      "Training Epoch 114 : 100%|██████████| 13/13 [00:07<00:00,  1.71it/s, disc_loss=0.259, gen_adv_loss=0.612, gen_pixel_loss=0.248]\n",
      "Training Epoch 115 : 100%|██████████| 13/13 [00:11<00:00,  1.17it/s, disc_loss=0.164, gen_adv_loss=0.559, gen_pixel_loss=0.255]\n",
      "Training Epoch 116 : 100%|██████████| 13/13 [00:07<00:00,  1.82it/s, disc_loss=0.184, gen_adv_loss=0.317, gen_pixel_loss=0.247]\n",
      "Training Epoch 117 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.108, gen_adv_loss=0.476, gen_pixel_loss=0.251]\n",
      "Training Epoch 118 : 100%|██████████| 13/13 [00:08<00:00,  1.60it/s, disc_loss=0.0886, gen_adv_loss=0.545, gen_pixel_loss=0.251]\n",
      "Training Epoch 119 : 100%|██████████| 13/13 [00:11<00:00,  1.09it/s, disc_loss=0.0773, gen_adv_loss=0.511, gen_pixel_loss=0.26] \n",
      "Training Epoch 120 : 100%|██████████| 13/13 [00:07<00:00,  1.65it/s, disc_loss=0.0916, gen_adv_loss=0.513, gen_pixel_loss=0.239]\n",
      "Training Epoch 121 : 100%|██████████| 13/13 [00:09<00:00,  1.44it/s, disc_loss=0.11, gen_adv_loss=0.467, gen_pixel_loss=0.248]  \n",
      "Training Epoch 122 : 100%|██████████| 13/13 [00:07<00:00,  1.69it/s, disc_loss=0.12, gen_adv_loss=0.437, gen_pixel_loss=0.267] \n",
      "Training Epoch 123 : 100%|██████████| 13/13 [00:11<00:00,  1.13it/s, disc_loss=0.109, gen_adv_loss=0.504, gen_pixel_loss=0.256]\n",
      "Training Epoch 124 : 100%|██████████| 13/13 [00:07<00:00,  1.75it/s, disc_loss=0.156, gen_adv_loss=0.482, gen_pixel_loss=0.265]\n",
      "Training Epoch 125 : 100%|██████████| 13/13 [00:06<00:00,  1.90it/s, disc_loss=0.148, gen_adv_loss=0.492, gen_pixel_loss=0.247]\n",
      "Training Epoch 126 : 100%|██████████| 13/13 [00:14<00:00,  1.08s/it, disc_loss=0.136, gen_adv_loss=0.517, gen_pixel_loss=0.251]\n",
      "Training Epoch 127 : 100%|██████████| 13/13 [00:07<00:00,  1.68it/s, disc_loss=0.216, gen_adv_loss=0.444, gen_pixel_loss=0.246]\n",
      "Training Epoch 128 : 100%|██████████| 13/13 [00:07<00:00,  1.74it/s, disc_loss=0.198, gen_adv_loss=0.404, gen_pixel_loss=0.249]\n",
      "Training Epoch 129 : 100%|██████████| 13/13 [00:06<00:00,  1.86it/s, disc_loss=0.203, gen_adv_loss=0.37, gen_pixel_loss=0.25]  \n",
      "Training Epoch 130 : 100%|██████████| 13/13 [00:09<00:00,  1.32it/s, disc_loss=0.177, gen_adv_loss=0.374, gen_pixel_loss=0.247]\n",
      "Training Epoch 131 : 100%|██████████| 13/13 [00:06<00:00,  1.89it/s, disc_loss=0.222, gen_adv_loss=0.307, gen_pixel_loss=0.255]\n",
      "Training Epoch 132 : 100%|██████████| 13/13 [00:07<00:00,  1.80it/s, disc_loss=0.206, gen_adv_loss=0.368, gen_pixel_loss=0.251]\n",
      "Training Epoch 133 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.207, gen_adv_loss=0.356, gen_pixel_loss=0.242]\n",
      "Training Epoch 134 : 100%|██████████| 13/13 [00:10<00:00,  1.20it/s, disc_loss=0.188, gen_adv_loss=0.339, gen_pixel_loss=0.254]\n",
      "Training Epoch 135 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.18, gen_adv_loss=0.408, gen_pixel_loss=0.254] \n",
      "Training Epoch 136 : 100%|██████████| 13/13 [00:06<00:00,  1.86it/s, disc_loss=0.184, gen_adv_loss=0.429, gen_pixel_loss=0.247]\n",
      "Training Epoch 137 : 100%|██████████| 13/13 [00:07<00:00,  1.63it/s, disc_loss=0.177, gen_adv_loss=0.332, gen_pixel_loss=0.25] \n",
      "Training Epoch 138 : 100%|██████████| 13/13 [00:08<00:00,  1.47it/s, disc_loss=0.172, gen_adv_loss=0.364, gen_pixel_loss=0.246]\n",
      "Training Epoch 139 : 100%|██████████| 13/13 [00:06<00:00,  2.16it/s, disc_loss=0.217, gen_adv_loss=0.318, gen_pixel_loss=0.236]\n",
      "Training Epoch 140 : 100%|██████████| 13/13 [00:06<00:00,  2.06it/s, disc_loss=0.198, gen_adv_loss=0.402, gen_pixel_loss=0.243]\n",
      "Training Epoch 141 : 100%|██████████| 13/13 [00:06<00:00,  2.02it/s, disc_loss=0.22, gen_adv_loss=0.348, gen_pixel_loss=0.25]  \n",
      "Training Epoch 142 : 100%|██████████| 13/13 [00:10<00:00,  1.29it/s, disc_loss=0.205, gen_adv_loss=0.392, gen_pixel_loss=0.246]\n",
      "Training Epoch 143 : 100%|██████████| 13/13 [00:06<00:00,  1.99it/s, disc_loss=0.15, gen_adv_loss=0.556, gen_pixel_loss=0.237] \n",
      "Training Epoch 144 : 100%|██████████| 13/13 [00:06<00:00,  2.01it/s, disc_loss=0.22, gen_adv_loss=0.379, gen_pixel_loss=0.247] \n",
      "Training Epoch 145 : 100%|██████████| 13/13 [00:06<00:00,  2.05it/s, disc_loss=0.16, gen_adv_loss=0.584, gen_pixel_loss=0.238] \n",
      "Training Epoch 146 : 100%|██████████| 13/13 [00:08<00:00,  1.47it/s, disc_loss=0.149, gen_adv_loss=0.462, gen_pixel_loss=0.242]\n",
      "Training Epoch 147 : 100%|██████████| 13/13 [00:06<00:00,  2.15it/s, disc_loss=0.151, gen_adv_loss=0.654, gen_pixel_loss=0.241]\n",
      "Training Epoch 148 : 100%|██████████| 13/13 [00:06<00:00,  1.98it/s, disc_loss=0.326, gen_adv_loss=0.227, gen_pixel_loss=0.248]\n",
      "Training Epoch 149 : 100%|██████████| 13/13 [00:06<00:00,  1.89it/s, disc_loss=0.215, gen_adv_loss=0.29, gen_pixel_loss=0.242] \n",
      "Training Epoch 150 : 100%|██████████| 13/13 [00:11<00:00,  1.14it/s, disc_loss=0.164, gen_adv_loss=0.424, gen_pixel_loss=0.245]\n",
      "Training Epoch 151 : 100%|██████████| 13/13 [00:07<00:00,  1.81it/s, disc_loss=0.174, gen_adv_loss=0.427, gen_pixel_loss=0.233]\n",
      "Training Epoch 152 : 100%|██████████| 13/13 [00:07<00:00,  1.66it/s, disc_loss=0.178, gen_adv_loss=0.43, gen_pixel_loss=0.239] \n",
      "Training Epoch 153 : 100%|██████████| 13/13 [00:09<00:00,  1.31it/s, disc_loss=0.154, gen_adv_loss=0.425, gen_pixel_loss=0.245]\n",
      "Training Epoch 154 : 100%|██████████| 13/13 [00:07<00:00,  1.80it/s, disc_loss=0.221, gen_adv_loss=0.556, gen_pixel_loss=0.233]\n",
      "Training Epoch 155 : 100%|██████████| 13/13 [00:06<00:00,  1.89it/s, disc_loss=0.131, gen_adv_loss=0.539, gen_pixel_loss=0.24] \n",
      "Training Epoch 156 : 100%|██████████| 13/13 [00:06<00:00,  2.16it/s, disc_loss=0.0877, gen_adv_loss=0.695, gen_pixel_loss=0.241]\n",
      "Training Epoch 157 : 100%|██████████| 13/13 [00:12<00:00,  1.08it/s, disc_loss=0.139, gen_adv_loss=0.549, gen_pixel_loss=0.231]\n",
      "Training Epoch 158 : 100%|██████████| 13/13 [00:10<00:00,  1.20it/s, disc_loss=0.175, gen_adv_loss=0.528, gen_pixel_loss=0.239]\n",
      "Training Epoch 159 : 100%|██████████| 13/13 [00:08<00:00,  1.57it/s, disc_loss=0.307, gen_adv_loss=0.67, gen_pixel_loss=0.237] \n",
      "Training Epoch 160 : 100%|██████████| 13/13 [00:07<00:00,  1.79it/s, disc_loss=0.311, gen_adv_loss=0.566, gen_pixel_loss=0.237]\n",
      "Training Epoch 161 : 100%|██████████| 13/13 [00:09<00:00,  1.33it/s, disc_loss=0.263, gen_adv_loss=0.324, gen_pixel_loss=0.234]\n",
      "Training Epoch 162 : 100%|██████████| 13/13 [00:06<00:00,  1.99it/s, disc_loss=0.256, gen_adv_loss=0.215, gen_pixel_loss=0.241]\n",
      "Training Epoch 163 : 100%|██████████| 13/13 [00:05<00:00,  2.17it/s, disc_loss=0.257, gen_adv_loss=0.214, gen_pixel_loss=0.232]\n",
      "Training Epoch 164 : 100%|██████████| 13/13 [00:06<00:00,  1.95it/s, disc_loss=0.26, gen_adv_loss=0.215, gen_pixel_loss=0.229] \n",
      "Training Epoch 165 : 100%|██████████| 13/13 [00:09<00:00,  1.39it/s, disc_loss=0.256, gen_adv_loss=0.218, gen_pixel_loss=0.24] \n",
      "Training Epoch 166 : 100%|██████████| 13/13 [00:06<00:00,  1.98it/s, disc_loss=0.255, gen_adv_loss=0.226, gen_pixel_loss=0.225]\n",
      "Training Epoch 167 : 100%|██████████| 13/13 [00:06<00:00,  2.01it/s, disc_loss=0.255, gen_adv_loss=0.227, gen_pixel_loss=0.242]\n",
      "Training Epoch 168 : 100%|██████████| 13/13 [00:07<00:00,  1.78it/s, disc_loss=0.249, gen_adv_loss=0.255, gen_pixel_loss=0.24] \n",
      "Training Epoch 169 : 100%|██████████| 13/13 [00:12<00:00,  1.01it/s, disc_loss=0.251, gen_adv_loss=0.284, gen_pixel_loss=0.24] \n",
      "Training Epoch 170 : 100%|██████████| 13/13 [00:07<00:00,  1.84it/s, disc_loss=0.247, gen_adv_loss=0.31, gen_pixel_loss=0.235] \n",
      "Training Epoch 171 :  23%|██▎       | 3/13 [00:04<00:11,  1.11s/it, disc_loss=0.244, gen_adv_loss=0.309, gen_pixel_loss=0.219]"
     ]
    }
   ],
   "source": [
    "for experiment in Experiments:\n",
    "    train(experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d867856c3cc7357577fc7fd8f34dc4f0c6a87331577ca13d81d866fff482f970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
